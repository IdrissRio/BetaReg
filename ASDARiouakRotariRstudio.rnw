\documentclass[twoside,twocolumn]{article}
\usepackage{graphicx}
\usepackage{fancyvrb}
\usepackage{listings}
\usepackage{bm}
\usepackage{xcolor}
\xdefinecolor{gray}{rgb}{0.4,0.4,0.4}
\xdefinecolor{blue}{RGB}{58,95,205}% R's royalblue3; #3A5FCD
\usepackage{float}
\lstset{% setup listings
	language=R,% set programming language
	basicstyle=\ttfamily\small,% basic font style
	keywordstyle=\color{blue},% keyword style
	commentstyle=\color{gray},% comment style
	numbers=none,% display line numbers on the left side
	numberstyle=\scriptsize,% use small line numbers
	numbersep=10pt,% space between line numbers and code
	backgroundcolor = \color{yellow!10},
	framexleftmargin = 1em,
	framextopmargin = 1em
	framexbottommargin = 1em
	tabsize=3,% sizes of tabs
	showstringspaces=false,% do not replace spaces in strings by a certain character
	captionpos=b,% positioning of the caption below
	breaklines=true,% automatic line breaking
	escapeinside={(*}{*)},% escaping to LaTeX
	fancyvrb=true,% verbatim code is typset by listings
	extendedchars=false,% prohibit extended chars (chars of codes 128--255)
	literate={"}{{\texttt{"}}}1{<-}{{$\bm\leftarrow$}}1{<<-}{{$\bm\twoheadleftarrow$}}1
	{~}{{$\bm\sim$}}1{<=}{{$\bm\le$}}1{>=}{{$\bm\ge$}}1{!=}{{$\bm\neq$}}1{^}{{$^{\bm\wedge}$}}1,% item to replace, text, length of chars
	alsoletter={.<-},% becomes a letter
	alsoother={$},% becomes other
	otherkeywords={!=, ~, $, \&, \%/\%, \%*\%, \%\%, <-, <<-, /},% other keywords
	deletekeywords={c}% remove keywords
}
\usepackage{stackengine}
\usepackage{blindtext} 
\usepackage{amsmath}
\usepackage[sc]{mathpazo} 
\usepackage[T1]{fontenc} 
\usepackage{tabularx}
\linespread{1.05} 
\usepackage{microtype} 
\usepackage{amssymb}
\usepackage[italian]{babel} 
\usepackage{tikz}
\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} 
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} 
\usepackage{booktabs} 
\usepackage{tocbibind}
\newtheorem{theorem}{Teorema}
\newtheorem{lemma}{Lemma}
\newcommand{\listofalgorithmes}{\tocfile{\listalgorithmcfname}{loa}}
\usepackage{lettrine} 
\usepackage{graphicx} 
\usepackage{enumitem} 
\setlist[itemize]{noitemsep} 
\usetikzlibrary{shapes.misc, positioning}
\usepackage{abstract} 
\renewcommand{\abstractnamefont}{\normalfont\bfseries}
\renewcommand{\abstracttextfont}{\normalfont\small\itshape} 
\usepackage{titlesec} 
\renewcommand\thesection{\Roman{section}} 
\renewcommand\thesubsection{\roman{subsection}} 
\newcommand{\notimplies}{%
	\mathrel{{\ooalign{\hidewidth$\not\phantom{=}$\hidewidth\cr$\implies$}}}}
\titleformat{\section}[block]{\large\scshape\centering}{\thesection.}{1em}{} 
\titleformat{\subsection}[block]{\large}{\thesubsection.}{1em}{}
\usepackage{fancyhdr} 
\pagestyle{fancy} 
\fancyhead{} 
\fancyfoot{} 
\fancyhead[C]{BetaReg $\bullet$ Applied Statistic and Data Analysis} % Custom header text
\fancyfoot[RO,LE]{\thepage} 

\usetikzlibrary{positioning}

\newcommand{\LivelloReale}{Livello reale}
\newcommand{\LivelloAstratto}{Livello astratto }
\newcommand{\qzero}{$q_0$}
\newcommand{\quno}{$q_1$}
\newcommand{\qdue}{$q_2$}
\newcommand{\qtre}{$q_3$}
\newcommand{\qzerohat}{$\hat{q_0}$}
\newcommand{\qunohat}{$\hat{q_1}$}
\newcommand{\yslant}{0.5}
\newcommand{\xslant}{-0.6}

\usepackage{titling}

\usepackage{hyperref} 

\usepackage{algorithm2e} %for psuedo code
 \SetKwProg{Fn}{function}{}{end-function}
  \SetKwProg{Try}{try}{}{}
  \SetKwProg{Catch}{catch}{}{end}
 \RestyleAlgo{boxed}
%\usepackage[lmargin=3.81cm,tmargin=2.54cm,rmargin=2.54cm,bmargin=2.52cm]{geometry}

\def\rlwd{.4pt}
\def\rlht{1.1pt}
\def\shatvrule{\rule{\rlwd}{\rlht}}
\def\shat#1{%
	\setbox0=\hbox{$#1$}%
	\stackon[0pt]{\stackon[1pt]{\ensuremath{#1}}{%
			\shatvrule\kern\wd0\kern-\rlwd\kern-\rlwd\shatvrule}}%
	{\rule{\wd0}{\rlwd}}%
}

\setlength{\droptitle}{-4\baselineskip} 

\pretitle{\begin{center}\Huge\bfseries} 
	\posttitle{\end{center}} 
\title{Un pacchetto R: betareg} 
\author{
	\textsc{Marta Rotari - Idriss Riouak} \\[1ex] 
	\normalsize Università degli studi di Udine \\ 
	\normalsize Dipartimento di matematica e informatica \\ 
	\normalsize Applied Statistic and Data Analysis\\
	\normalsize \href{mailto:idriss.riouak@spes.uniud.it}{idriss.riouak@spes.uniud.it} 
	\normalsize \href{mailto:marta.rotari@spes.uniud.it}{marta.rotari@spes.uniud.it} 
}
\date{\today} 
\renewcommand{\maketitlehookd}{%
	\begin{abstract}
		\noindent  La regressione permette l'analisi delle relazioni che intercorrono tra due variabili che possono assumere valori nel continuo o nel discreto. Lo scopo di questa relazione è quello di studiare e analizzare un modello di regressione nel quale il dominio delle variabili di risposta possono assumere valori nell'intervallo limitato $(0,1)$.
		Il modello analizzato è chiamato modello di regressione con variabili di risposta Beta, introdotto per la prima volta nel 2004 da Cribari-Neto e Ferrari \cite{2004}. In particolare andremo ad analizzare l'implementazione in \emph{R} del modello, analizzando il pacchetto \texttt{betareg}.
	\end{abstract}
}


\begin{document}
	

	\maketitle
	
	\section{Introduzione}
	Un modello di regressione è un modello statistico, il cui scopo è sia quello di studiare ed analizzare le relazioni tra una una variabile \emph{dipendente} ($y$), detta variabile di risposta, e una o più variabili \emph{indipendenti} ($x$), dette variabili regressori, e anche quello di effettuare predizioni dato un nuovo valore per la variabile $x$.
	
	Il \emph{modello di regressione lineare semplice} ha la seguente forma
	\begin{equation}\label{eq:lrm}
		 y_i=\alpha + \beta x_i + \varepsilon_i 
	\end{equation}

	dove la componente casuale $\varepsilon_i$ è normalmente distribuita con media zero e varianza $\sigma^2$.
	Tale modello è ampiamente utilizzato in svariate applicazione, tuttavia non è appropriato per situazioni in cui la variabile risposta è limitata ad assumere valori in un intervallo $(0,1)$, in quanto, i valori stimati potrebbero eccedere tale intervallo\footnote{Un esempio classico è <<Teaching Program>>\cite{PV}(pg. 67)}. Per ovviare a tale problema, prima dell'avvento del modello di regressione con variabili \textit{Beta}, la variabile di risposta $y$ veniva trasformata per poter assumere valori in $\mathbb{R}$, per esempio applicando la seguente trasformazione $\tilde{y}=log(\frac{y}{1-y})$ alla quale veniva applicato il modello di regressione lineare semplice. Ma tale approccio presentava alcune problematiche come: interpretare i parametri rispetto a $E[\tilde{y}]$ anziché rispetto a $E[y]$; le variabili casuali con valori nell'intervallo unitario sono tipicamente eteroschedastiche che causano la mancanza di alcune ipotesi fondamentali nel modello di regressione lineare (la varianza aumenta all'avvicinarsi della media e decresce spostandosi verso i limiti dell'intervallo) ed infine l'asimmetria della distribuzione dei tassi e delle proporzioni dunque la stima degli intervalli per il test dell'ipotesi basate su approssimazioni Gaussiane portavano a grosse imprecisioni sopratutto in campioni di piccole dimensioni.

	Nel 2004, Cribari-Neto e Ferrari, con l'articolo \emph{"Beta Regression for Modelling Rates and Proportions"} \cite{2004}, propongono un nuovo modello di regressione per variabili continue con valori in $(0,1)$, come possono essere proporzioni e tassi, assumendo che la variabile risposta sia beta-distribuita. Successivamente nel 2016, nell'articolo \emph{``Beta Regression in R''} \cite{CNF}, i due autori forniscono un'implementazione in R di tale modello.
	
	\section{Beta distribuzione}
	Come già anticipato, il modello di regressione Beta si basa sull'ipotesi che la variabile risposta $y$ sia \textit{beta}-distribuita.
	La distribuzione Beta e una distribuzione di probabilità continua definita da due parametri $p$ e $q$ sul''intervallo unitario $[0,1]$\footnote{Si noti che se la variabile $y$ dovesse assumere valori nell'intervallo $(a,b)$, dove $a < b$ e siano valori noti, allora è possibile modellare $\frac{y-a}{b-a}$ al posto di $y$. Mentre se la variabile $y$ dovesse assumere come valori in [0,1], una possibile trasformazione potrebbe essere $\frac{y\cdot (n-1) \cdot 0.5}{n}$ dove $n$ è la grandezza del campione.}. Questa distribuzione governa la probabilità $p$ di un processo di Bernoulli a posteriori dell'osservazione di $\alpha -1$ successi e $\beta -1$ insuccessi quando $p$  è a priori distribuita uniformemente tra $0$ e $1$. 
	
	La funzione densità di probabilità di una variabile casuale beta è data nel seguente modo:
	$$f(y;p,q)=\frac{\Gamma(p+q)}{\Gamma(p)\Gamma(q)}y^{p-1}(1-y)^{q-1},\ \ \ \ 0 <y<1$$ 
	Dove $p>0$ e $q>0$ e $\Gamma(\cdot)$ è la funzione gamma $\Gamma(z)=\int_{0}^{+ \infty} t^{z-1} e^{-t} dt.$ 
	
	\emph{Ferrari e Cribari-Neto} ne hanno proposto una parametrizzazione differente per il suo utilizzo nel modello:

	$$
		\hspace{-4mm}
	f(y;\mu,\phi)=\frac{\Gamma({\phi})}{\Gamma(\mu\phi)\Gamma((1-\mu)\phi)}y^{\mu\phi{-1}}(1-y)^{(1-\mu)\phi-1} $$
	con 
	\begin{align*}
	\mu&=\frac{p}{p+q} \ , & \phi=p+q
	\end{align*}
	dove $0<\mu<1$, $\phi >0 $ e $0<y<1$. 
		\begin{figure*}[ht]
		\centering
		\includegraphics[scale=.5]{BetaDistribution}
		\caption{Rappresentazione grafica della distribuzione Beta, utilizzando il comando R: \emph{dbeta2}.}
	\end{figure*}
	
	
	
	Denoteremo con $y \sim \mathbb{\mathcal{B}}(\mu,\phi)$ se  la v.c. $y$ segue una beta distribuzione con parametri $\mu$ e $\phi$. Si noti che $p=\mu\phi$ e $q=\phi(1-\mu)$, da cui segue che $$E(y)=\mu \ \ e \ \ V(y)=\frac{V(\mu)}{1+\phi}=\frac{\mu(1-\mu)}{1+\phi}.$$ 
	
	Il parametro $\phi$ è anche chiamato \emph{parametro di precisione}, in quanto per $\mu$ fissato, all'aumentare di $\phi$ diminuisce il valore della varianza.

\section{Il modello di regressione Beta}
Sia $y_1, y_2, ... ,y_n$ un campionamento casuale tale che $\forall_{i=1}^n: y_i \sim \mathbb{\mathcal{B}}(\mu_i, \phi)$. Il modello di regressione Beta è definito nel seguente modo
\begin{equation}g(\mu_i)=x_i^t\beta=\eta_i
\label{eq:mui}
\end{equation}
dove $\beta=(\beta_1, \beta_2, ..., \beta_k)^t$, con $k<n$, è un vettore $k \times 1$, $x_i=(x_{i1}, x_{i2},...,x_{ik})^t$ è un vettore di $k$ variabili esplicative, per convenzione $x_{i1}=1$ in tal modo ogni modello ha l'intercetta; mentre $\eta_i=\beta_1x_{i1}+...+\beta_kx_{ik}$ è un predittore lineare. Infine $g(\cdot):(0,1)\rightarrow\mathbb{R}$ è una funzione $\mathcal{C}^2$, detta funzione di collegamento, avente derivata seconda costante. Le funzioni di collegamento più utilizzate sono:
%%FIX-ME: Aggiungere commenti e dettagliare le funzioni di collegamento.
\begin{itemize}
	\item \textbf{logit:} $g(\mu)=log(\frac{\mu}{(1-\mu)}) $
	\item \textbf{probit:} $g(\mu)=\varPhi^{-1}(\mu)$, dove $\varPhi(\cdot)$ è la funzioni di distribuzione normale standard.
	\item \textbf{log-log complementare:}\\ $g(\mu)=\log(-\log(1-\mu))$
	\item \textbf{log-log:} $g(\mu)=\log(-\log(\mu))$
	\item \textbf{Cauchy:} $g(\mu)=\tan(\pi(\mu-0.5))$
\end{itemize}

Denotiamo con $l(\beta,\phi)=\sum_{i=1}^{n}l_i(\mu_i,\phi)$ la funzione di verosimiglianza, dove 
\begin{align*}
l_i(\mu_i, \phi)=&\log \Gamma(\phi)-\log \Gamma(\mu_i\phi)\\
&-\log\Gamma((1-\mu_i)\phi)+(\mu_i\phi-1)\log y_i \\&
+  \{(1-\mu_i)\phi -1 \}\log(1-y_i)
\end{align*}
con $\mu_i$ definito come nell'equazione \eqref{eq:mui} ovvero $\mu_i=g^{-1}(x_i^t\beta)$.

Nel 2010 è stata formulata un'estensione del modello a dispersione variabile considerando il parametro di precisione non più costante per tutte le osservazioni ma modellato come parametro della media. Le osservazioni diventano  $y_i \sim \mathbb{\mathcal{B}}(\mu_i, \phi_i)$ indipendenti con 
\begin{align}
g_1(\mu_i)&=\eta_{1i}=x{_i}^T \beta, \label{eq:mean}\\
g_2(\phi_i)&=\eta_{2i}=z{_i}^T \gamma, \label{eq:precisione}
\end{align}
dove $\beta=(\beta_1,....,\beta_k)^T  \  e \ \gamma=(\gamma_1,..,\gamma_h)^T \ con \  k+h<n$ insiemi dei coefficienti di regressione, $x_i \ e \ z_i$ vettori di reggressori e $\eta_{1i} \ e \ \eta_{21} $ predittori lineari. 

Per quanto riguarda i residui vengono usati  i residui di Pearson che Ferrari e Cribari chiamano residui ordinari standardizzati:
$$r_{P,i=\frac{y_i-\hat{\mu}_i}{\sqrt{\hat{V}(y_i)}}}$$  dove $\hat{V}(y_i)=\frac{\hat{\mu}_i(1-\hat{\mu}_i)}{(1+\hat{\psi}_i)}$ con $\hat{\mu}_i=g_1 ^{-1}(x_i ^T \hat{\beta}) \ e \ \hat{\phi_i}=g_2^{-1}(z_i ^T \hat{\gamma}_i)$.

Ferrari e Cribari-Neto nell'elaborato del (2008,\cite{RESIDUAL}) danno una nuova versione dei residui con proprietà migliori chiamandoli residui standardizzati pesati 2:

$$r_{SW2,i}=\frac{y_i ^* - \hat{\mu}_i ^*}{\sqrt{\hat{v_i}(1-h_ii)}}$$
dove $y_i ^* = \log\{y_i/(1-y_i)\} \ e \ \mu _i ^* = \psi (\mu_i \phi)-\psi ((1-\mu_i)\phi)$ con $\psi (\cdot)$ la funzione standardizzata di digamma. Si standardizza poi utilizzando $v_i= {\psi ' (\mu_i\phi)+\psi '((1-\mu_i)\phi)}$ e $h_{ii}'$ la i-esima componente della matrice  hat.

	\subsection{Determinizzazione degli stimatori.}
%%FIX-ME: determinare qual'è l'intervallo di t di \mu e y.
Si considerino le notazioni appena introdotte $$y_i^*=\log\bigg(\frac{y_i}{1-y_i}\bigg)$$ e $$\mu_i^*=\psi(\mu_i\phi)-\psi((1-\mu_i)\phi),$$ dove $\psi(x)=\frac{\partial \log \Gamma(x)}{\partial x}$ con $x>0$ è detta funzione \emph{digamma.} Denotiamo con $$\nabla(\beta,\phi)=\begin{pmatrix}
U_\beta(\beta,\phi)\\U_\phi(\beta,\phi)
\end{pmatrix}$$
la funzione \emph{score}, ottenuta differenziando la funzione di log-verosimiglianza rispetto i due parametri ignoti. Dunque 
$$U_\beta(\beta,\phi)=\frac{\partial l(\beta,\phi)}{\partial \beta}=\phi X^tT(y^*-u^*), $$
dove $X$ è la matrice del modello di dimensione $n \times k$, $T$ è una matrice diagonale la cui dimensione $n \times n$ definita come $T=diag\{g'(\mu_1)^{-1},...,g'(\mu_n)^{-1}\}$, $y^*=(y_1^*, ..., y_n^*)$ e $\mu^*=(\mu_1^*, ..., \mu_n^*)$. Mentre \begin{align*}
U_\phi(\beta,\phi)=&\sum_{i=1}^{n}\{ \mu_i(y_i^*-\mu_i^*)
+ log(1-y_i)\\ & - \phi((1-\mu_i)\psi)+ \phi(\psi)  \}
\end{align*}
Quindi gli stimatori di massima verosimiglianza (MLEs) per $\beta$ e $\phi$ sono ottenibili ponendo rispettivamente $U_\beta(\beta,\phi)$ e $U_\phi(\beta,\phi)$ uguali a zero.
Tale tipo di equazioni non sono risolvibili analiticamente, ma il risultato può essere approssimato attraverso un  algoritmo numerico come l'algoritmo di \emph{Newton}. Tali algoritmi necessitano di un punto di partenza ($\beta_0,\phi_0$), che nel caso di $\beta$ utilizzando il metodo dei minimi quadrati è $$ \beta_0=(X^tX)^{-1}X^tz,$$ dove  $z=(g(y_1),...,g(y_n))^t$.
Mentre per $\phi$, \emph{Ferrari e Cribari-Neto} in \cite{2004} suggeriscono  come punto di partenza $$
\phi_0=\frac{1}{n}\sum_{i=1}^{n}\frac{\breve{\mu}_i(1-l\breve{\mu}_i)}{\breve{\sigma}_i^2},
$$
dove $\breve{\mu}_i$ è ottenuto applicando la funzione $g^{-1}(\cdot)$ al \emph{i-esimo} valore stimato dal modello di regressione lineare di $g(y_1),...,g(y_n)$ su $X$: $$\breve{\mu}_i=g^{-1}(x_i^t(X^tX)^{-1}X^t z)$$  e $$ \breve{\sigma}_i^2=\frac{\breve{e}^t\breve{e}}{(n-k)[g'(\breve{\mu})_i]^2} $$
dove $\breve{e}=z-X(X^tX)^{-1}X^tz$.

Consideriamo ora la matrice d'informazione di \emph{Fisher}, che servirà per poter approssimare l'errore standard degli stimatori $\hat{\beta}$ e $\hat{\phi}$. Poniamo prima $W=diag\{w_1,...,w_n\}$, con $$w_i=\phi\{\psi'(\mu_i\phi)+ \psi'((1-\mu_i)\phi) \}\frac{1}{\{g'(\mu_i)\}^2}, $$ $c=(c_1,...,c_n)^t$,  dove $$c_i=\phi\{\psi'(\mu_i\phi)\mu_i-\phi'((1-\mu_i)\phi)(1-\mu_i) \}$$
e $\psi'(\cdot)$ è la funzione \emph{trigamma} $\psi'(x)=\frac{\partial^2}{\partial x^2}\log \Gamma(x).$
Sia dunque $K$ la matrice d'informazione di \emph{Fisher}:

\begin{equation}
 K = K(\beta,\phi) =
 	 \begin{pmatrix} 
 	 	K_{\beta\beta} & K_{\beta\phi}\\
 	 	K_{\phi\beta} & K_{\phi\phi} 
 	 \end{pmatrix}, 
 	 \label{eq:Fisher}
\end{equation}
dove 
\begin{itemize}
	\item $K_{\beta\beta}=\phi X^tWX$,
	\item $K_{\beta\phi}=K_{\phi_\beta}^t=X^tTc$,
	\item $K_{\phi \phi}=tr(D)$.
\end{itemize}

Sotto le condizioni di normalità, d'indipendenza e di omogeneità di varianza delle variabili, quando la numerosità del campione è elevata, vale che
$$ \begin{pmatrix}\hat{\beta}\\ \hat{\phi} \end{pmatrix} \sim \mathcal{N}_{k+1}\Bigg(\begin{pmatrix}\beta\\ \phi \end{pmatrix},K^{-1}\Bigg).$$ 

Denoteremo con $SE(\hat{\beta_j})$ l'errore standard asintotico del MLE $\hat{\beta_j}$, che si ottiene dall'inversa della matrice di \emph{Fisher} \eqref{eq:Fisher} valutata in $\hat{\beta_j}$ e in $\hat{\phi}$.

\subsection{Intervallo di confidenza}
E' possibile determinare un intervallo di confidenza $(1-\alpha)100\%$\footnote{con $\alpha \in (0,\frac{1}{2})$.} per i coefficienti $\hat{\beta}_j$, con $j=1,...,k$. Tale intervallo è:
$$ \bigg[\hat{\beta_j} \pm \Phi^{-1}\bigg(1-\frac{\alpha}{2}SE(\hat{\beta_j})\bigg)\bigg], $$
dove $\Phi(\cdot)$ è la funzione di distribuzione cumulativa di una variabile casuale normale. 

Analogamente un intervallo di confidenza $(1-\alpha)100\%$ per il parametro $\hat{\phi}$ è il seguente
$$\bigg[\hat{\phi} \pm \Phi^{-1}\bigg(1-\frac{\alpha}{2}SE(\hat{\phi})\bigg)  \bigg] $$ dove 
\begin{align*}
SE(\hat{\phi})&=\sqrt{tr(D)-\phi^{-1}c^tT^tX(X^tWX)^{-1}X^tTc}\\
&=\sqrt{\hat{\gamma}}.
\end{align*}

Infine è possibile determinare un intervallo di confidenza $(1-\alpha)100\%$ per il valore atteso della variabile risposta $\mu$ per un dato vettore d'osservazioni delle variabili regressori $x_0=[1,x_{01},x_{02},...,x_{0k}]$:
$$[Lim_{sx}, Lim_{dx}]\footnote{Tale intervallo è valido solo per funzioni di collegamento $g(\cdot)$ strettamente crescenti.}$$ dove 
$$Lim_{sx}=\bigg[ g^{-1}\bigg(\hat{\eta} -\Phi^{-1}\Big(\frac{1-\alpha}{2}\Big)SE(\hat{\eta})\bigg)  \bigg]  $$
mentre
$$ Lim_{dx}=\bigg[ g^{-1}\bigg(\hat{\eta} +\Phi^{-1}\Big(\frac{1-\alpha}{2}\Big)SE(\hat{\eta})\bigg)  \bigg], $$
con $\hat{\eta}=x_0^t \hat{\beta}$ e $SE(\hat{\eta})=\sqrt{x_0^t \widehat{\text{Cov}}(\hat{\beta})x_0}$ dove $\widehat{\text{Cov}}(\hat{\beta})$ è ottenuto dall'inversa della matrice di \emph{Fisher} \eqref{eq:Fisher} valutata negli MLEs escludendo la riga e la colonna relative al parametro di precisione $\hat{\phi}$.
\newpage
\onecolumn
\section{Pacchetto Betareg}
Il pacchetto BetaReg è una collezione di funzioni implementate in ``R system for statistica computing",  con il quale è possibile modellare variabili dipendenti beta distribuite. Il pacchetto è disponibile presso il \emph{``Comprehensive R Archive Network" (CRAN).} Le versioni dalla 1.0 alla 1.2 sono state implementate da \emph{Simas e Rocha} fino al 2006. Dalla versione 2.0, il principale contribuente alla manutenzione e all'estensione del pacchetto è stato \emph{Achim Zeileis}, coautore dell'articolo \cite{BReg2006}.
\begin{lstlisting}[caption={Signature della funzione betareg()},label={lst:signature}]
betareg(formula, data, subset, na.action, weights, offset,
link = "logit", link.phi = NULL, control = betareg.control(...), model = TRUE, y = TRUE, x = FALSE, ...)
\end{lstlisting}
La main-function \texttt{betareg()} è stata progettata e implementata per essere il più simile possibile alla funzione standard \texttt{glm()} (General Linear Model).
Nel listing \ref{lst:signature} viene data la \emph{signature} della funzione di model-fitting \texttt{betareg()}. Verrà ora data una breve descrizione degli argomenti della funzione:
\begin{itemize}
	\item \texttt{formula}: descrizione simbolica del modello, e.g.: \texttt{y $\sim$ x+z}
	\item \texttt{data, subset:} sorgente dei dati.
	\item \texttt{na.action:} funzione che descrive come comportarsi dinnanzi a elementi \texttt{NA}.
	\item \texttt{weights}: vettore di pesi. 
	\item \texttt{link:} specifica la funzione di collegamento. Le possibili scelte sono: \texttt{logit, probit, cloglog, cauchit, log, loglog}. Il valore di default è \texttt{logit}.
	\item \texttt{link.phi}: specifica la funzione di collegamento per il parametro di precisione $\phi$. La scelte possibili sono: \texttt{identity, sqrt, log}.
	\item \texttt{control}: prende come parametro un oggetto di tipo \texttt{betareg.control}.
	\item \texttt{model, x, y}: argomenti di tipo logico (\texttt{TRUE, FALSE}). Se impostati a  \texttt{TRUE}, vengono restituiti il \emph{model.frame, model matrix} e il \emph{vettore della variabile risposta} rispettivamente.
\end{itemize}
L'opzione \texttt{control} prende come parametro un oggetto di tipo \texttt{betareg.control}. Tali oggetti servono per controllare la modalità con la quale veogno stimati i coefficienti del modello.
\begin{lstlisting}
betareg.control(phi = TRUE, method = "BFGS", maxit = 5000,
      hessian = FALSE, trace = FALSE, start = NULL,
      fsmaxit = 200, fstol = 1e-8, ...)
\end{lstlisting}
Di seguito una descrizione di tali opzioni:
\begin{itemize}
  \item \texttt{phi}: valore booleano. Indica se il parametro $\phi$ deve essere trattato come un parametro del modello o come un parametro di disturbo.
  \item \texttt{method}: specifica quale metodo numerico viene utilizzato per stimare i coefficienti. Il valore di default è \texttt{BFGS}.
  \item \texttt{maxit}: indica il numero massimo di iterate da eseguire.
  \item \texttt{trace:} valore booleno. Indica se deve essere mantenuta traccia delle iterazioni effettuate durante la stima dei coefficienti.
  \item \texttt{hessian:} valore booleano. Indica se deve essere utilizzato l'Hessiano per stimare la matrice delle covariate. L'opzione di default è \texttt{FALSE}.
  \item \texttt{start:} un vettore di valori opzionali che indica quali sono in punti di partenza per stimare i coefficienti del modello. Si veda la sezione \texttt{III.i}.
  \item \texttt{fsmaxit:} valore intero. Indica il numero massimo delle iterazioni del \textit{punteggio di Fisher}.
  \item \texttt{fstol:} valore numerico. Indica la tolleranza dell'errore per raggiungere la convergenza.
\end{itemize}

L'oggetto restituito dal modello stimato della classe \texttt{betareg} è una lista simile a quella restituita dagli oggetti \texttt{glm}, dove troviamo \texttt{coefficients} e \texttt{terms}. E' possibile interrogare gli oggetti della classe \texttt{betareg} attraverso la funzione \texttt{summary()}. Nella tabella \ref{MethodTable}, è stata riporta una lista dei metodi e delle funzioni offerte dagli oggetti della classe \texttt{betareg}. 

\begin{table}[t]
	\centering
	\caption{Principali funzioni e metodi per gli oggetti della classe \texttt{betareg}}
	\label{MethodTable}
	\begin{tabularx}{\textwidth}{|l|X|}
		\hline
		\textbf{FUNZIONE}  & \textbf{DESCRIZIONE}               \\ \hline
		\texttt{print()}            & Stampa su standard output i coefficienti stimati.                          \\
		\texttt{summary()}          & Stampa su standard output la stima dei coefficienti, l'errore standard e il test parziale di Wald. Restituisce un oggetto della classe \texttt{summary.betareg}.                        \\ \hline
		\texttt{coef()}             & Restituisce tutti i coefficienti del modello, compresi intercetta e coefficiente di  precisione.                      \\
		\texttt{vcoef()}            & Restituisce la matrice della covarianza.                        \\
		\texttt{predict()}          & Funzione di predizione del valor atteso, dei predittori lineari, del parametro di precisione e delle varianze.                        \\
		\texttt{fitted()}           & Valori attesi stimati per un nuovo vettore di osservazioni.                 \\
		\texttt{residual()}         & Restituisce il vettore dei residui.                    \\
		\texttt{terms()}            & Restituisce i componenti del modello.       \\
		\texttt{model.matrix()}     & Restituisce la \emph{Matrice del Modello} \\
		\texttt{model.frame()}      & Restituisce l'intero frame di dati del modello.                       \\
		\texttt{loglik()}           & Restituisce la stima di log-verosimiglianza.                    \\ \hline
		\texttt{plot()}             & Stampa sul device grafico i plot dei residui, delle predizioni, dei punti di leva etc.                            \\
		\texttt{hatvalues}          & Restituisce un vettore di elementi rappresentanti la diagonale della matrice \emph{hat}.                     \\
		\texttt{cocks.distance}     & Restituisce un'approssimazione della distanza di Cook.                     \\
		\texttt{glevarage()}        & Restituisce un vettore di elementi con rappresentanti il valore di leva di ogni punto.                      \\ \hline
		\texttt{coeftest()}         & Test parziale di Wald dei coefficienti.                             \\
		\texttt{waldtest()}        & Test di Wald per modelli annidati.                      \\
		\texttt{linear.hypotesis()} &  Test di Wald per ipotesi lineari.                \\
		\texttt{AIC()}           & Calcola l'Aikaike Information Criteria (AIC) e altri Information Criteria come il BIC.                      \\ \hline
	\end{tabularx}
\end{table}



Di seguito un esempio per fissare le idee: consideriamo la seguente \texttt{formula} $$\mathtt{y \sim x_1+x_2}$$ che descrive $y_i$ e $x_i$ per l'equazione \eqref{eq:mean} mentre per l'equazione \eqref{eq:precisione} avremo $\phi_i$ costante e di conseguenza $z_i=1$ e la funzione di collegamento $g_2$ la funzione identità, che corrisponde al modello base definito nel (2004) senza variabili di dispersione.
 Possiamo specificare un secondo insieme di regressori tramite la formula two-part nel seguente modo:
 $$\mathtt{y \sim x_1+x_2 | z_1+z_2+z_3}$$ 
in questo caso abbiamo la stessa formulazione dell'equazione \eqref{eq:mean} mentre per l'equazione \eqref{eq:precisione} $\phi_i$ non è più costante. I regressori $z_i$ vengo presi dalla \texttt{$z_1+z_2+z_3$}, alla funzione di collegamento viene assegnata la funzione logaritmo cioè $g_2(\cdot)=log(\cdot).$
\section{Esempi implementativi}
Nella seguente sezione verranno analizzati e commentati due esempi di dataset presenti del pacchetto \texttt{betareg}.
\subsection{Esempio: gasoline}
Nella seguente sezione verrà considerato un esempio a scopo illustrativo. L'insieme di dati preso in considerazione è relativo alla quota di petrolio greggio trasformato in benzina dopo la distillazione. Le variabili presenti nel dataset sono:
\begin{itemize}
	\item \texttt{yield:} tasso di petrolio greggio trasformato in benzina dopo la distillazione.
	\item \texttt{gravity:} gravità del petrolio greggio.
	\item \texttt{pressure:} pressione della materiale grezzo (libre/pollice$^2$). 
	\item \texttt{temp10}: temperatura per la quale il 10\% di petrolio greggio vaporizza.
	\item \texttt{temp}: temperatura per la quale il 100\% di petrolio greggio vaporizza.
	\item \texttt{batch}: variabile fattore di 10 livelli. Ognuno di essi ha una propria gravità, pressione e temperatura d'evaporazione al 10\%.
\end{itemize}

<<eval=TRUE>>=
library(betareg)
data("GasolineYield", package = "betareg")
str(GasolineYield)
@
Si procede dunque caricando la libreria \texttt{betareg}, dopo di che viene considerato un modello di regressione Beta di tipo omoschedastico, analizzando il rapporto tra le variabili regressioni \texttt{batch} e \texttt{temp} rispetto la variabile risposta \texttt{yield}. Il modello è stato adattato 
 attraverso le istruzioni \texttt{m1<-betareg(yield $\sim$ batch+temp, data=GasolineYield)} con la seguente analisi del \texttt{summary(m1)}. L'output ottenuto della funzione \texttt{summary} è simile a quello degli oggetti \texttt{glm}.
In particolare troviamo:
\begin{itemize}
\item Riepiloghi numerici relativi ai residui pesati standard come \texttt{Min, 1Q, Median, 3Q} e \texttt{Max}. 
\item Gli MLE dei coefficienti del vettore $\beta$ e del parametro di precisione $\phi$ con il relativo errore standard $SE(\hat{\phi})$.
\item I valori del Wald test (\texttt{z value}) per verificare l'ipotesi di nullità dei coefficienti, con il relativo \emph{p-valore} (\texttt{Pr(>|z|)}).
\item Il valore massimo della log-verosimiglianza.
\item Il valore del coefficiente $R^2$-adjusted.
\item Il numero di iterazioni del metodo BFGS effettuate per stimare i parametri.
\end{itemize}


<<eval=TRUE>>=
m1 <- betareg(yield~batch+temp, data=GasolineYield)
summary(m1)
@
Come si può vedere, tutti i coefficienti, compreso quello di precisione, sono significativi in quanto hanno un basso \emph{p-valore}. A confermare l'evidente relazione tra le variabili regressori e la variabile risposta è l'indice $R^2$-adjusted con un valore di \emph{0.9617}.

Come per gli oggetti della classe \texttt{glm}, attraverso la funzione \texttt{plot} è possibile visualizzare i grafici diagnostici.

<<eval=TRUE>>=
par(pty="s",cex.axis=1.3,cex.lab=1.3, mar=c(5,3,1.5,1))
layout(matrix(c(1:7,7,7),byrow=TRUE,nrow=3))
plot(m1, which = 1, type = "pearson", sub.caption = "")
plot(m1, which = 1, type = "deviance", sub.caption = "")
plot(m1, which = 3)
plot(m1, which = 5, type = "deviance", sub.caption = "")
plot(m1, which = 4, type = "pearson", sub.caption = "")
plot(m1, which = 6, type = "pearson", sub.caption = "")
par(pty="m")
plot(m1, which = 2)
@
Analizzando il plot rappresentante le \emph{distanze di Cook}, si può notare che la quarta osservazione ha il valore più alto rispetto tutte le altre e supera il valore \emph{0.5}. Andrebbe dunque considerata una versione del modello, stimato sugli stessi punti del modello \texttt{m1} omettendo la quarta osservazione.
<<eval=TRUE>>=
m2 <- betareg(yield~batch+temp, data=GasolineYield,subset=-4)
summary(m2)
@
Omettendo la quarta osservazione è possibile notare una diminuzione della varianza ovvero un aumento del coefficiente di precisione da $\hat{\phi}_{m1}=$440.27 a $\hat{\phi}_{m2}=$557.79.

Consideriamo ora un nuovo modello, dove andiamo ad esplicitare il coefficiente di precisione. In particolare utilizzeremo come parametro di precisione la variabile esplicativa \texttt{temp}.

<<eval=TRUE>>=
m1.eteroske <- betareg(yield~batch+temp | temp, data=GasolineYield)
summary(m1.eteroske)
@
Non avendo esplicitato alcuna funzione di collegamento per $g_2(\cdot)$, è stata utilizzata quella di default, ovvero quella di tipo \texttt{logit}.
Attraverso la funzione \texttt{lmtest::lrtest} è possibile effettuare un confronto tra il modello \texttt{m1.eteroske} e \texttt{m1} utilizzando il test di ratio-verosimiglianza. 
<<eval=TRUE>>=
lmtest::lrtest(m1,m1.eteroske)
@
Il p-value (<0.5) è un evidenza contro l'omoschedasticità del modello \texttt{m1}, ovvero viene rifiutata l'ipotesi nulla che $g_2(\cdot)$ sia costante.
Un'ulteriore test che confermi il fatto che il parametro $\phi$ non sia costante è dato dal test di Wald:
<<eval=TRUE>>=
lmtest::waldtest(m1,m1.eteroske)
@
Si noti che anche in questo caso il p-value suggerisce il rigetto dell'ipotesi nulla.

Consideriamo ora un modello omoschedastico simile a \texttt{m1}, con funzione di collegamento per la media \texttt{probit}:
<<eval=TRUE>>=
m1.probit<-betareg(yield~batch+temp, link="probit", data=GasolineYield)
summary(m1.probit)
@
Si può notare un leggero incremento del coefficiente del parametro $\phi$ e dell'indice $R^2$-adjusted.
<<eval=TRUE>>=
summary(m1.probit)$pseudo.r.squared-summary(m1)$pseudo.r.squared
AIC(m1,m1.probit)
BIC(m1,m1.probit)
@
Si può notare che utilizzando come funzione di collegamento la funzione \texttt{probit} rispetto quella standard (\texttt{logit}) porta  miglioramenti poco significativi. Il risultato dell'AIC e della differenza tra i due indici $R^{2}$-adjusted ne danno conferma.

In fine verrà considerato un modello in cui viene utilizzata la funzione di collegamento \texttt{loglog}:
<<eval=TRUE>>=
m1.loglog<-betareg(yield~batch+temp, link="loglog", data=GasolineYield)
summary(m1.loglog)
@
\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{LogLogFittedValue}
\caption{In \color{red} rosso \color{black} i punti stimati dal modello \texttt{m1.loglog} (-). In \color{blue} blu \color{black} i \texttt{segments} rappresentanti i valori residui. }
\end{figure}
Come si può vedere dall'output della funzione \texttt{summary}, sia il coefficiente del parametro di precisione che il l'indice $R^2$-adjusted sono significativamente maggiori rispetto ai modelli analizzati precedentemente. Un ulteriore conferma è data dall'indice AIC.
<<eval=TRUE>>=
AIC(m1,m1.eteroske,m1.probit,m1.loglog)
@
\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{gasolinePlot3}
\caption{Nel seguente plot sono riportate le \emph{fitted curves}: in \color{red} rosso \color{black} il modello \texttt{m1.loglog}, in \color{blue}blu \color{black} il modello \texttt{m1} ed in fine il modello \texttt(m1.probit) in \color{gray} grigio. \color{black}}
\end{figure}


\subsection{Esempio 2: Spese domestiche per gli alimenti}
Consideriamo un secondo esempio sempre nell'ambito betareg che consiste nel trovare la dipendenza della variabile dipendente \texttt{food/income} la proporzione di redditto che ogni famiglia spende nell'acquisto degli alimenti. Le variabili regressori sono: la variabile numerica \texttt{persons} componenti della famiglia e ovviamente la variabile \texttt{income} totale di tutte le entrate della famiglia. 

Consideriamo il modello di regressione lineare per il dataset:

<<eval=TRUE>>=
data("FoodExpenditure",package = "betareg")
mod.regressione<-lm(I(food/income) ~ income+persons, data = FoodExpenditure)
@

\begin{figure}[H]
\centering
\includegraphics[scale=0.25]{primo_es2}
\caption{A sinistra la fitted curves del modello di regressione lineare. A destra il plot diagnostico rappresentante  i fitted values rispetto la radice quadrata del valore assoluto dei residui standardizzati.}
\end{figure}

Insieme al grafico che riproduce la fitted curve del modello di regressione lineare è stato eseguito anche uno dei grafici diagnostici per il controllo della varianza tramite il plot dei fitted values e la radice del valore assoluto dei residui standardizzati utilizzando \texttt{which=3}. A prima vista la varianza non appare costante, per poterlo confermare eseguiamo dei test.


Vogliamo vedere se il modello preso in considerazione è eteroschedastico. Per la verifica utilizziamo il \textit{Test di Breusch e Pagan} che verificare l'ipotesi di omoschedasticità, applicando ai residui gli stessi concetti della regressione lineare. Esso è valido per campioni di dimensioni elevate e assume che gli errori siano indipendenti e normalmente distribuiti e che la loro varianza $\sigma_t ^2$ sia funzione lineare del tempo. Come ipotesi nulla, considera la funzione logaritmo della varianza definita prima, costante. Troviamo questo test nella \texttt{library("lmtest")} con il nome di \texttt{(bptest)} 

<<eval=TRUE>>=
library("lmtest")
bptest(mod.regressione)
@

Possiamo vedere dal p-value che l'ipotesi nulla viene rifiuta, in favore di una varianza non costante. Concludiamo che il modello presenta eteroschedasticità, quindi il modello di beta regressione è più appropriato. Come funzione di collegamento viene considerata quella di default 
<<eval=TRUE>>=
library("betareg")
data("FoodExpenditure",package = "betareg")
beta_regressione<-betareg(I(food/income) ~ income+persons, data = FoodExpenditure)
summary(beta_regressione)
@
\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{secondo_es2}
\caption{A confronto in \color{blue} blu \color{black} il modello  \texttt{beta\_regressione} e in \textbf{nero} il modello \texttt{mod.regressione}. }
\end{figure}

Mettendo a confronto entrambi i modelli possiamo vedere che in realtà non differiscono molto. Le fitted curves differiscono poco una dall'altra ciò significa che i modelli restituiscono risultati simili. 
Da entrambi possiamo concludere che la percentuale è più elevata per famiglie a poco reddito significa che la spesa per gli alimenti incide notevolmente sul budget famigliare. La percentuale del reddito  speso per gli alimenti scende all'aumentare del reddito delle famiglie, cioè la spesa incide meno sul budget famigliare. La spesa aumenta inoltre all'aumentare dei componenti delle famiglie. Ma questo aumento non viene catturato bene dal modello beta in questo caso. Decidiamo quindi di aggiungere la variabile \texttt{persons} come variabile regressore aggiuntiva nell'equazione di precisione. Consideriamo quindi il seguente modello con variabile di dispersione.

<<eval=TRUE>>=
library("betareg")
data("FoodExpenditure",package = "betareg")
beta_regressione_persons<-betareg(I(food/income) ~ income+persons|persons, 
                                  data = FoodExpenditure)
@

Mettiamo subito a confronto i due modelli tramite \texttt{lrtest}

<<eval=TRUE>>=
library("lmtest")
lrtest(beta_regressione,beta_regressione_persons)
AIC(beta_regressione,beta_regressione_persons)
BIC(beta_regressione,beta_regressione_persons)
@
Da entrambi gli indici AIC e BIC troviamo un evidente miglioramento nel modello con variabile di dispersione.

Fino ad ora è stata considerata la funzione di collegamento \texttt{logit}, vogliamo vedere se avviene otteniamo un miglioramento utilizzando altre funzioni di collegamento. Lo si può fare con una singola istruzione:

<<eval=TRUE>>=
sapply(c("logit","probit","cloglog","cauchit","loglog"),
       function(x)logLik(update(beta_regressione_persons,link=x)))
@
Notiamo che le funzione di collegamento hanno un effetto molto simile, l'unica che si distingue leggermente e la \texttt{"cauchit"} con un valore leggermente più alto. Vediamo le fitted curves graficamente


\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{fine_es2}
\caption{Confronto tra i tre modelli: in \color{red} rosso \color{black} il modello \texttt{beta\_regressione}, in \color{blue} blu \color{black} il modello \texttt{beta\_regressione\_persons} ed infine in \textbf{nero} il modello \texttt{beta\_regressione\_persons\_cauchit}. }
\end{figure}




\clearpage
\tableofcontents
	\begin{thebibliography}{9} 
	\bibitem{2004} \textbf{Beta Regression for Modelling Rates and Proportions.}, Ferrari SLP, Cribari-Neto Francisco (2004).  Journal of Applied Statistics, 31(7), 799–815.
	\bibitem{CNF} \textbf{Beta Regression in R}, Francisco Cribari-Neto, Achim Zeileis.\\
	\bibitem{PV} \textbf{Towards multiple linear regression and logistic regression}, Paolo Vidoni, 2017-2018. Lecture 5. Applied Statistics and Data Analysis.
	\bibitem{BReg2006}\textbf{betareg 1.2} - Simas AB, Rocha (2006). betareg: Beta Regression. R package \\ \texttt{http://CRAN.R-project.org/src/contrib/ Archive/betareg/}.
	\bibitem{RESIDUAL}\textbf{On Beta Regression Residuals} Espinheira PL, Ferrari SLP, Cribari-Neto F (2008b). Journal
of Applied Statistics, 35(4), 407–419.
\end{thebibliography}

\end{document}